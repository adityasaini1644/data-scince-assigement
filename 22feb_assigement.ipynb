{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "video_urls = []\n",
    "videos = soup.find_all(\"a\", {\"class\": \"yt-simple-endpoint style-scope ytd-grid-video-renderer\"})\n",
    "for video in videos[:5]:\n",
    "    video_url = \"https://www.youtube.com\" + video[\"href\"]\n",
    "    video_urls.append(video_url)\n",
    "\n",
    "with open(\"video_urls.csv\", \"w\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Video URL\"])\n",
    "    for video_url in video_urls:\n",
    "        writer.writerow([video_url])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "video_thumbnails = []\n",
    "for thumbnail in soup.select('a#thumbnail'):\n",
    "    if len(video_thumbnails) < 5:\n",
    "        video_thumbnails.append(thumbnail['href'])\n",
    "\n",
    "with open('video_thumbnails.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for thumbnail in video_thumbnails:\n",
    "        writer.writerow([thumbnail])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Write a python program to extract the title of the first five videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import csv\n",
    "\n",
    "# Set up YouTube Data API v3 credentials\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "client_secrets_file = \"YOUR_CLIENT_SECRET_FILE.json\"  # Replace with your client secret file path\n",
    "flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    client_secrets_file, scopes)\n",
    "credentials = flow.run_console()\n",
    "youtube = googleapiclient.discovery.build(api_service_name, api_version, credentials=credentials)\n",
    "\n",
    "# Set up query parameters to fetch video data\n",
    "channel_id = \"CHANNEL_ID\"  # Replace with the channel ID of the YouTube channel you want to fetch data for\n",
    "max_results = 5\n",
    "\n",
    "# Fetch video data\n",
    "request = youtube.search().list(\n",
    "    part=\"snippet\",\n",
    "    channelId=channel_id,\n",
    "    maxResults=max_results,\n",
    "    order=\"date\",\n",
    "    type=\"video\"\n",
    ")\n",
    "response = request.execute()\n",
    "\n",
    "# Extract video titles and save to CSV file\n",
    "with open('video_titles.csv', mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['Title']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for item in response['items']:\n",
    "        video_title = item['snippet']['title']\n",
    "        writer.writerow({'Title': video_title})\n",
    "        print(video_title)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Make a request to the URL\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract the first five video links\n",
    "video_links = soup.select(\"a#video-title\")\n",
    "\n",
    "# Extract the number of views of each video\n",
    "views = []\n",
    "for link in video_links[:5]:\n",
    "    video_url = \"https://www.youtube.com\" + link[\"href\"]\n",
    "    video_response = requests.get(video_url)\n",
    "    video_soup = BeautifulSoup(video_response.content, \"html.parser\")\n",
    "    view_count = video_soup.select_one(\"span.view-count\").text.strip()\n",
    "    views.append(view_count)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "with open(\"youtube_data.csv\", \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Video Title\", \"Number of Views\"])\n",
    "    for i in range(5):\n",
    "        writer.writerow([video_links[i].text.strip(), views[i]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "times = []\n",
    "for video in videos[:5]:\n",
    "    time = video['time']  \n",
    "    times.append(time)\n",
    "\n",
    "# Save the data into a CSV file\n",
    "with open('video_times.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Time of Posting'])\n",
    "    for time in times:\n",
    "        writer.writerow([time])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
